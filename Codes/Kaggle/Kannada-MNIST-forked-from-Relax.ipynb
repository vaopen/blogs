{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint,History,EarlyStopping,LearningRateScheduler\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:]\n",
    "val = data[55000:]\n",
    "train_label = np.float32(train.label)\n",
    "val_label = np.float32(val.label)\n",
    "train_image = np.float32(train[train.columns[1:]])\n",
    "val_image = np.float32(val[val.columns[1:]])\n",
    "test_image = np.float32(test_data[test_data.columns[1:]])\n",
    "print('train shape: %s'%str(train.shape))\n",
    "print('val shape: %s'%str(val.shape))\n",
    "print('train_label shape: %s'%str(train_label.shape))\n",
    "print('val_label shape: %s'%str(val_label.shape))\n",
    "print('train_image shape: %s'%str(train_image.shape))\n",
    "print('val_image shape: %s'%str(val_image.shape))\n",
    "print('test_image shape: %s'%str(test_image.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 独热编码\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "yy = [[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]\n",
    "encoder.fit(yy)\n",
    "# 转置\n",
    "train_label = train_label.reshape(-1,1)\n",
    "val_label = val_label.reshape(-1,1)\n",
    "# 独热编码\n",
    "train_label = encoder.transform(train_label)\n",
    "val_label = encoder.transform(val_label)\n",
    "\n",
    "print('train_label shape: %s'%str(train_label.shape))\n",
    "print('val_label shape: %s'%str(val_label.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_image[13].reshape(28,28))\n",
    "plt.show()\n",
    "print(train_image[13].shape)\n",
    "\n",
    "train_image = train_image/255.0\n",
    "val_image = val_image/255.0\n",
    "test_image = test_image/255.0\n",
    "\n",
    "train_image = train_image.reshape(train_image.shape[0],28,28,1)\n",
    "val_image = val_image.reshape(val_image.shape[0],28,28,1)\n",
    "test_image = test_image.reshape(test_image.shape[0],28,28,1)\n",
    "print('train_image shape: %s'%str(train_image.shape))\n",
    "\n",
    "print('train_image shape: %s'%str(train_image.shape))\n",
    "print('val_image shape: %s'%str(val_image.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        assert units % 32 == 0\n",
    "        self.k = units // 32\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        k = self.k\n",
    "        self.conv_1_1 = tf.keras.layers.Conv2D(\n",
    "            filters=8*k,\n",
    "            kernel_size=[1, 1],\n",
    "            strides=1,\n",
    "            padding='same'\n",
    "        )\n",
    "        self.conv_1_1_t3 = tf.keras.layers.Conv2D(\n",
    "            filters=12*k,\n",
    "            kernel_size=[1, 1],\n",
    "            strides=1,\n",
    "            padding='same'\n",
    "        )\n",
    "        self.conv_3_3 = tf.keras.layers.Conv2D(\n",
    "            filters=16*k,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=1,\n",
    "            padding='same'\n",
    "        )\n",
    "        self.conv_1_1_t5 = tf.keras.layers.Conv2D(\n",
    "            filters=k,\n",
    "            kernel_size=[1, 1],\n",
    "            strides=1,\n",
    "            padding='same'\n",
    "        )\n",
    "        self.conv_3_3_t5 = tf.keras.layers.Conv2D(\n",
    "            filters=2*k,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=1,\n",
    "            padding='same'\n",
    "        )\n",
    "        self.conv_5_5 = tf.keras.layers.Conv2D(\n",
    "            filters=4*k,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=1,\n",
    "            padding='same'\n",
    "        )\n",
    "        self.pool_t = tf.keras.layers.MaxPool2D(\n",
    "            pool_size=[3, 3],\n",
    "            strides=1,\n",
    "            padding='same'\n",
    "        )\n",
    "        self.pool = tf.keras.layers.Conv2D(\n",
    "            filters=4*k,\n",
    "            kernel_size=[1, 1],\n",
    "            strides=1,\n",
    "            padding='same'\n",
    "        )\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_1_1 = self.conv_1_1(inputs)\n",
    "        x_1_1_t3 = self.conv_1_1_t3(inputs)\n",
    "        x_3_3 = self.conv_3_3(x_1_1_t3)\n",
    "        x_1_1_t5 = self.conv_1_1_t5(inputs)\n",
    "        x_3_3_t5 = self.conv_3_3_t5(x_1_1_t5)\n",
    "        x_5_5 = self.conv_5_5(x_3_3_t5)\n",
    "        x_pool_t = self.pool_t(inputs)\n",
    "        x_pool = self.pool(x_pool_t)\n",
    "        x = tf.concat([x_1_1, x_3_3, x_5_5, x_pool], axis=-1)\n",
    "        x = self.bn(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "x = inputs\n",
    "x = InceptionModule(units=64, activation=tf.nn.relu)(x)\n",
    "x = InceptionModule(units=64, activation=tf.nn.relu)(x)\n",
    "x = InceptionModule(units=128, activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)(x)\n",
    "\n",
    "res = x\n",
    "x = InceptionModule(units=128, activation=tf.nn.relu)(x)\n",
    "x = InceptionModule(units=128, activation=tf.nn.relu)(x)\n",
    "x = InceptionModule(units=128, activation=None)(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x += res\n",
    "\n",
    "res = x\n",
    "x = InceptionModule(units=128, activation=tf.nn.relu)(x)\n",
    "x = InceptionModule(units=128, activation=tf.nn.relu)(x)\n",
    "x = InceptionModule(units=128, activation=None)(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x += res\n",
    "\n",
    "res = x\n",
    "x = InceptionModule(units=128, activation=tf.nn.relu)(x)\n",
    "x = InceptionModule(units=128, activation=tf.nn.relu)(x)\n",
    "x = InceptionModule(units=128, activation=None)(x)\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x += res\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)(x)\n",
    "\n",
    "x = InceptionModule(units=128, activation=tf.nn.relu)(x)\n",
    "x = InceptionModule(units=128, activation=tf.nn.relu)(x)\n",
    "x = InceptionModule(units=128, activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[3, 3], strides=2, padding='same')(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=10, kernel_size=[1, 1], padding='same')(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = tf.keras.layers.Softmax()(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1),padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.7))\n",
    "\n",
    "# model.add(Conv2D(128, kernel_size=3, activation='relu',padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(128, kernel_size=3, activation='relu',padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.7))\n",
    "\n",
    "# model.add(Conv2D(256, kernel_size=3, activation='relu',padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.7))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256,kernel_regularizer=regularizers.l2(0.02)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.7))\n",
    "# model.add(Dense(128,kernel_regularizer=regularizers.l2(0.02)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.7))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "learning_rate = 2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay(epoch):#lrv\n",
    "    return learning_rate * 0.99 ** epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(lr=learning_rate),metrics=['accuracy'])\n",
    "# 匹配数据\n",
    "datagen.fit(train_image)\n",
    "\n",
    "# 训练\n",
    "history = model.fit_generator(datagen.flow(train_image,train_label, batch_size=BATCH_SIZE),\n",
    "                              epochs = EPOCHS,\n",
    "                              validation_data = (val_image,val_label),\n",
    "                              verbose = 1,\n",
    "                              callbacks=[LearningRateScheduler(lr_decay)],\n",
    "                              steps_per_epoch=train_image.shape[0] // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练 & 验证的准确率值\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = model.predict(test_image)\n",
    "label = np.argmax(label,1)\n",
    "id_ = np.arange(0,label.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = pd.read_csv('/kaggle/input/Kannada-MNIST/sample_submission.csv')\n",
    "print(sim.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = pd.DataFrame({'id':id_,'label':label})\n",
    "print(save.head(10))\n",
    "save.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
